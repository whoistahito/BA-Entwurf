\chapter{State of the Art}

The limitations of current job-matching systems, as outlined in the introduction, have led researchers to explore more sophisticated approaches capable of capturing the semantic relationships between job descriptions, requirements, and user profiles. Over the past years, the field has evolved from simple keyword-based methods toward advanced semantic, transformer-based, and large-scale industrial systems. This chapter provides an overview of these developments, focusing on those techniques that inform the design of the system proposed in this thesis.


\section{Semantic and Transformer-Based Job Matching}

Early improvements over keyword matching emerged through semantic similarity models, which aimed to interpret the conceptual relevance between resumes and job descriptions. Research by Ajjam and Al-Raweshidy \cite{ajjam_ai-driven_2025} demonstrated that these approaches outperform keyword-based methods, achieving significantly higher similarity scores and enabling a more nuanced interpretation of the conceptual relevance between resumes and job descriptions.

The adoption of transformer models marked a major shift in this domain. Architectures such as BERT and its derivatives \cite{sentence-bert} enabled richer contextual understanding and improved generalization across career‑related tasks. The development of domain-specific models represented a pivotal advancement in this field. For instance, Rosenberger et al. proposed CareerBERT, a novel approach that leverages the power of unstructured textual data sources, that uses jobGBERT \cite{gbert} to embed resumes and job categories derived from the standardized European Skills, Competences, and Occupations (ESCO) taxonomy \cite{careerbert}. By pre-training on specialized career data, such models create a shared embedding space that more accurately captures the intricacies of professional qualifications. Their approach demonstrated comparable, though more reliable, performance to that of GPT-4 while exhibiting significantly superior computational efficiency \cite{careerbert}.

These developments highlight the steady shift toward embedding-based architectures capable of encoding job content beyond surface-level keywords. However, most domain-specific transformer models rely heavily on curated data sources or custom pretraining pipelines, which limits accessibility.


\section{Industrial-Scale Recommender Architectures}

Parallel to academic research, large technology companies have integrated semantic embeddings into production‑level recommender systems. CareerBuilder, for example, developed an embedding-based recommender system that constructs fused embeddings from text, semantic entities, and location data to handle matching at a massive scale \cite{zhao2021embeddingbasedrecommender}. Their two-stage process, involving approximate nearest neighbor search followed by a reranking model, led to significant gains in user engagement and match quality.
LinkedIn's LinkSAGE framework represents a significant advancement in the field of network analysis, incorporating Graph Neural Networks (GNN) to model the intricate and interwoven relationships within its professional network \cite{linksage}. LinkSAGE is using GraphSAGE architecture, which is  ``a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data'' \cite{graphsage}. By conceptualizing members, employment opportunities, and competencies as nodes in a comprehensive graph, LinkSAGE is able to capture implicit signals and deliver highly relevant recommendations. Despite its effectiveness, this architecture poses significant barriers for broader adoption: it depends on massive proprietary datasets and requires extensive computational infrastructure, making it unsuitable for open, platform-aggregating systems such as the one developed in this thesis.
Nevertheless, LinkSAGE demonstrates a key insight for the field: effective job matching requires modeling the detailed relationships between applicant skills and job requirements. This principle directly informs the methodology of the approach proposed in this thesis.


\section{Addressing Data Challenges: Augmentation and Hard-Negative Mining}

As semantic models grew more advanced, researchers increasingly focused on addressing data sparsity and imbalance—persistent challenges in recruitment datasets. The CONFIT V2 framework \cite{confitv2} introduces a novel strategy to enrich training data by using LLMs to generate hypothetical reference resumes. These synthetic examples are combined with Runner-Up Hard-Negative Mining, a technique that selects job–resume pairs which appear similar but are incorrect, forcing the model to learn subtle distinctions between suitable and unsuitable matches. This method significantly improves model robustness and highlights the growing role of generative AI in enhancing contrastive learning processes.

Although such methods push performance forward, they require substantial computational resources and specialized training pipelines. This dependency limits their applicability in lightweight, low-budget, or open-source contexts.


\section{Related Work}
Following the broader developments in job matching, this section examines research directly related to the two core techniques used in this thesis: (1) LLM‑based requirements extraction and (2) embedding-driven similarity search.

\subsubsection{Requirements Extraction using LLMs}
LLMs have demonstrated strong capabilities in transforming unstructured job descriptions into structured information. Howison et al. \cite{howison2024} demonstrated the use of generative AI to extract structured labor market data, such as education requirements and job types, from real-world job ads with statistically reliable results. Similarly, Herandi et al. \cite{herandiskilllm} proposed Skill-LLM, a fine-tuned LLM optimized for skill extraction, significantly outperforming standard Named Entity Recognition (NER) baselines in identifying hard skills.
While fine-tuned models achieve strong performance, they require task-specific annotations and training. In contrast, methods such as those explored by Nguyen et al. demonstrate that general-purpose LLMs can achieve competitive results through few-shot prompting, particularly when dealing with syntactically complex skill mentions \cite{nguyen2024rethinkingskillextractionjob}. This reinforces the choice of this thesis to rely on general-purpose, open-source LLMs without any fine-tuning, thereby increasing accessibility and adaptability.

\subsection{Embedding and Similarity Search in Job Matching}
\label{introduction:similaritysearch}
Embedding-based similarity search has become a cornerstone of modern job recommendation systems. Domain-specific models such as CareerBERT \cite{careerbert} achieve strong performance by leveraging structured taxonomies. However, general-purpose models such as sentence-transformers (e.g., all-MiniLM-L6-v2) have also shown excellent retrieval performance without task‑specific training, as demonstrated by Kurek et al. \cite{kurek2024}. Building on this foundation, this thesis employs the model to process extracted requirements, enabling the system to capture semantic relationships effectively.

\section{Research Gap} \label{sota:research_gap}


The literature reviewed in this chapter demonstrates considerable
progress in semantic job matching, domain‑specific transformer models,
graph‑based recommender architectures, and data‑augmentation techniques.
 Despite these advancements, several limitations persist:

\begin{itemize}
    \item Domain‑specific models frequently depend on extensive
preprocessing pipelines or proprietary datasets, which restricts their
accessibility and reproducibility.
    \item Industrial‑scale recommender systems require significant
computational infrastructure and rely on large, platform‑specific
datasets, making them unsuitable for deployment by smaller organizations
 or independent aggregators.
    \item Most of the state-of-the-art approaches rely on end-to-end embedding models that function as ``black boxes.'' While effective, these systems often obscure the specific rationale behind a match (e.g., whether a score is driven by skills, experience, or qualification), making it difficult to verify or explain recommendations.

\end{itemize}

To make these differences more explicit,
\autoref{tab:model_comparison} contrasts commercial job portals,
representative academic approaches, and the method proposed in this
thesis. The comparison highlights how this work distinguishes itself
through a combination of semantic capabilities, open‑source components,
and the absence of fine‑tuning requirements.


\begin{table}[h]
    \caption{Systematic Comparison of Job Matching Approaches}
    \label{tab:model_comparison}
    \centering
    \begin{tabular*}{\textwidth}{| l@{\extracolsep\fill} r || c | c | c | c |} % Added extra column
        \hline

        Tools &
        \rotatebox{90}{Characteristics} &
        \rotatebox{90}{Uses LLMs} &
        \rotatebox{90}{Open-Source} &
        \rotatebox{90}{Training Required} &
        \rotatebox{90}{Interpretability} \\

        \hline
        \hline

        \multicolumn{2}{|l||}{LinkSage} &
        \xmark  &
        \xmark  &
        \cmark &
        \xmark \\
        \hline

        \multicolumn{2}{|l||}{CareerBuilder} &
        \xmark &
        \xmark &
        \cmark &
        \xmark \\
        \hline

        \multicolumn{2}{|l||}{ConfitV2} &
        \cmark &
        \cmark &
        \cmark &
        \xmark \\

        \hline
        \multicolumn{2}{|l||}{Approach of this thesis} &
        \cmark &
        \cmark &
        \xmark &
        \cmark \\

        \hline

    \end{tabular*}
\end{table}


In summary, although existing systems achieve strong performance in specific settings, there remains no approach that is semantically robust, deployable using lightweight, fully open‑source components, and architecturally transparent. This thesis addresses this gap by proposing a job‑matching system that employs small open‑source LLMs for structured requirements extraction together with embedding‑based similarity search, thereby offering an accessible, computationally efficient, and interpretable-by-design alternative.
