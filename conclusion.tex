\chapter{Conclusion}

This thesis presented a novel, open-source approach to job matching that addresses the semantic limitations of traditional keyword-based search engines and the opacity of industrial recommendation systems. By integrating Large Language Model (LLM)-based requirements extraction with an embedding-driven similarity search, the proposed system demonstrates a viable path toward more transparent and semantically grounded job retrieval.

Regarding the first research question (RQ1), the evaluation confirmed that open-source LLMs can effectively extract structured job requirements from unstructured text without the need for task-specific fine-tuning. Integration of the outlines library successfully solved the challenge of syntactic validity, ensuring machine-readable output. However, the results indicate that the system is not yet at a production-ready level. While Qwen3-8B emerged as the best-performing model, it only achieved an aggregated overall score of 0.50 out of 1.0. Furthermore, critical semantic metrics such as Completeness and Alignment remained below 0.50 (0.45 and 0.50 respectively). This highlights a significant gap: while lightweight open-source models can be constrained to produce valid JSON structure, they still struggle with the semantic reasoning required to capture all mandatory requirements accurately without missing context or miscategorizing terms.

Regarding the second research question (RQ2), the comparison against LinkedInâ€™s recommendation engine showed that the proposed approach offers a more transparent and quantifiable matching logic. However, the system did not reach high similarity scores for the analyzed job postings. This low scoring can be linked to the weak requirement extraction process. As observed in the \autoref{sec:llm-performance}, the models frequently hallucinated requirements or included artifacts from the prompt instructions. These false negatives in the extracted data created a mismatch against the user profile, artificially lowering the similarity scores even for relevant job postings. Consequently, while the architecture provides a solid theoretical foundation, the current extraction quality introduces noise that lowers the reliability of the matching score.
Ultimately, this work contributes a modular, cost-effective architecture for job matching. By relying exclusively on lightweight open-source components, it democratizes access to advanced recruitment technologies, though significant improvements in extraction fidelity are required before it can compete with industrial-grade systems.

\section{Outlook}
\begin{enumerate}
\item Thinking models are not considered, Data Processing was not perfect (data imbalance),
\item bigger models,
\item  Readability metric for evaluation was not so effective, because the for exception handling it retuned an empty object, so there were no output that had syntax errors.
    \item How fast the whole process is has not been measured.
    \item add explaining ability of the system, that shows why a job is relevant to a user profile.
\end{enumerate}